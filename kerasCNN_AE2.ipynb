{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasCNN_AE2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akariiijima/AdversarialExample/blob/master/kerasCNN_AE2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSb4gU2yzcTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl8mhqkWzwoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"mnist_train.csv\")\n",
        "#1-10 labels\n",
        "labels=df[\"5\"].values\n",
        "#one-hot labels\n",
        "labels = tf.keras.utils.to_categorical(labels)\n",
        "\n",
        "df.drop(\"5\", axis=1, inplace=True)\n",
        "pixels=df.values\n",
        "pixels=pixels/255\n",
        "pixels=pixels.reshape(len(df),28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik0xNIb1ctQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdversarialLayer(keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "      super().__init__()\n",
        "      self.units = units\n",
        "    def build(self, input_shape):\n",
        "      #重みの定義\n",
        "      self.kernel = self.add_weight(\n",
        "      \"kernel\", shape=[int(input_shape[-1]), self.units],\n",
        "      initializer='glorot_uniform', trainable=True\n",
        "      )\n",
        "      #バイアスの定義\n",
        "      self.bias = self.add_weight(\n",
        "      \"bias\", shape=[self.units,],\n",
        "      initializer='zeros', trainable=False\n",
        "      )\n",
        "    def call(self, input):\n",
        "      output = tf.matmul(input, self.kernel)\n",
        "      output = tf.add(output, self.bias)\n",
        "      return tf.nn.relu(output)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cxOn3Jph0LU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "32f2d5ec-448f-4f96-aff7-f315255f226c"
      },
      "source": [
        "input = tf.constant([[1., 0., 0.], [0., 1., 0.]])\n",
        "layer = AdversarialLayer(5)\n",
        "print(input)\n",
        "print(layer(input))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_1:0\", shape=(2, 3), dtype=float32)\n",
            "Tensor(\"adversarial_layer_2/Relu:0\", shape=(2, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6xtpKOI0BU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelCNN=keras.Sequential([\n",
        "    #keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Conv2D(20, (3, 3), padding=\"valid\", activation=tf.nn.relu, input_shape=(28, 28,1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
        "    keras.layers.Conv2D(50, (3, 3), padding=\"valid\", activation=tf.nn.relu),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(225, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIxZHJgQOy_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1a0eca2d-d45e-46a6-cab7-13ee6077c605"
      },
      "source": [
        "modelCNN.compile(optimizer=tf.train.AdamOptimizer(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "modelCNN.summary()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_110 (Conv2D)          (None, 26, 26, 20)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_102 (MaxPoolin (None, 8, 8, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 6, 6, 50)          9050      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_103 (MaxPoolin (None, 2, 2, 50)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 2, 2, 50)          200       \n",
            "_________________________________________________________________\n",
            "flatten_87 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 225)               45225     \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 10)                2260      \n",
            "=================================================================\n",
            "Total params: 56,935\n",
            "Trainable params: 56,835\n",
            "Non-trainable params: 100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YICb1zZqWgnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eb851b13-88e8-4d55-ef31-a8e5c7bddd01"
      },
      "source": [
        "evaluate = modelCNN.evaluate(x=pixels, y=labels, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
        "print(modelCNN.metrics_names)\n",
        "evaluate"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59999/59999 [==============================] - 3s 57us/step\n",
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12901365068593076, 0.9609660161002683]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgvVs6lIWAzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "30fa0fa7-f824-48cd-ea9b-6c67e98ba5be"
      },
      "source": [
        "fit=modelCNN.fit(pixels, labels,epochs=10, batch_size=4096,validation_split=0.2)\n",
        "fit.history['loss']"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 47999 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0223 - acc: 0.9947 - val_loss: 0.0512 - val_acc: 0.9834\n",
            "Epoch 2/10\n",
            "47999/47999 [==============================] - 3s 60us/step - loss: 0.0208 - acc: 0.9950 - val_loss: 0.0539 - val_acc: 0.9823\n",
            "Epoch 3/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0193 - acc: 0.9955 - val_loss: 0.0476 - val_acc: 0.9842\n",
            "Epoch 4/10\n",
            "47999/47999 [==============================] - 3s 58us/step - loss: 0.0180 - acc: 0.9959 - val_loss: 0.0543 - val_acc: 0.9817\n",
            "Epoch 5/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0168 - acc: 0.9961 - val_loss: 0.0473 - val_acc: 0.9849\n",
            "Epoch 6/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0156 - acc: 0.9967 - val_loss: 0.0469 - val_acc: 0.9843\n",
            "Epoch 7/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0148 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9865\n",
            "Epoch 8/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0138 - acc: 0.9973 - val_loss: 0.0412 - val_acc: 0.9867\n",
            "Epoch 9/10\n",
            "47999/47999 [==============================] - 3s 59us/step - loss: 0.0129 - acc: 0.9976 - val_loss: 0.0444 - val_acc: 0.9849\n",
            "Epoch 10/10\n",
            "47999/47999 [==============================] - 3s 60us/step - loss: 0.0122 - acc: 0.9978 - val_loss: 0.0408 - val_acc: 0.9867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.022280924101905075,\n",
              " 0.020828009405227863,\n",
              " 0.01925884524898964,\n",
              " 0.017978081693566825,\n",
              " 0.01677995002130323,\n",
              " 0.01560666213681047,\n",
              " 0.014751679090585362,\n",
              " 0.013832652842934366,\n",
              " 0.012875582369768115,\n",
              " 0.012221509982917557]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IgnZkaUjg3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "e89073b3-26b5-4a44-cfa3-cbaeaf983d03"
      },
      "source": [
        "def input_derivative(model, x, goal):\n",
        "    \"\"\" Calculate derivatives wrt the intputs \"\"\"\n",
        "    y_true = keras.layers.Input(shape=(10,))\n",
        "    ce = keras.losses.categorical_crossentropy(y_true, model.output)\n",
        "    grad_ce = tf.keras.backend.gradients(ce, model.inputs)\n",
        "    # Create a function to be able to run this computation graph\n",
        "    func = keras.backend.function(model.inputs + [y_true], grad_ce)\n",
        "    output = func([x, goal])\n",
        "    return output\n",
        "\n",
        "def adversarial(model, n, steps, eta):\n",
        "    \"\"\"\n",
        "    model: MNIST model\n",
        "    n:     integer. goal label (just an int, the function transfroms it into a one-hot vector)\n",
        "    steps: integer. number of steps for gradient descent\n",
        "    eata:  integer. step size for gradient descent\n",
        "    \"\"\"\n",
        "    # Set the goal output\n",
        "    goal = tf.keras.utils.to_categorical(n, 10)\n",
        "    # Create a random image to initialize gradient descent with\n",
        "    x = np.random.normal(.5, .3, (1,784))\n",
        "    # Gradient descent on the input\n",
        "    for i in range(steps):\n",
        "      # Calculate the derivative\n",
        "      d = input_derivative(model, x, goal)\n",
        "      # The Gradient update on x\n",
        "      x -= eta*d[0]\n",
        "      print(\"step:{} done...\".format(i+1))\n",
        "    return x\n",
        "\n",
        "def generate(n):\n",
        "    \"\"\"\n",
        "    n: integer\n",
        "    goal label ( not hot vector)\n",
        "    \"\"\"\n",
        "    a = adversarial(model, n, 100, 1)\n",
        "    x = np.round(model.predict(a), 2)\n",
        "\n",
        "    plt.imshow(a.reshape(28,28), cmap='gray')\n",
        "\n",
        "\n",
        "def sneaky_adversarial(model, n, x_target, steps, eta, lam=0.5):\n",
        "    \"\"\"\n",
        "    model:    model object\n",
        "    n:        integer\n",
        "         our toal label\n",
        "    x_target: numpy vector\n",
        "         our goal image for the adversarial example\n",
        "    steps:    integer\n",
        "         number of steps for gradient descent\n",
        "    lam:      float\n",
        "         lambda, our regularization parameter. Default is 0.5\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the goal output\n",
        "    goal = tf.keras.utils.to_categorical(n, 10)\n",
        "    \n",
        "    # Create a random noise\n",
        "    x = np.random.normal(0.5, 0.3, (1,784))\n",
        "\n",
        "    \n",
        "    # Gradient descent on the input\n",
        "    for i in range(steps):\n",
        "      # Calculate the derivative\n",
        "      d = input_derivative(model, x, goal)\n",
        "      # The grads update on x, with an added penalty to the cost function\n",
        "      x -= eta * (d[0] + lam * (x - x_target))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def sneaky_generate(n, m):\n",
        "    \"\"\"\n",
        "    n:    int 0-9, the target number to match\n",
        "    m:    index of example image to use (from the test set)\n",
        "    \"\"\"\n",
        "    # Find random instance of m in test set\n",
        "    idx = np.random.randint(0,10000)\n",
        "    while np.where(y_test[idx] == 1)[0][0] != m: \n",
        "      idx += 1\n",
        "    # Hardcode the parameters for the wrapper function\n",
        "    a = sneaky_adversarial(model, n, x_test[idx], 10, 1)\n",
        "    x = np.round(model.predict(a), 2)\n",
        "    print('\\nWhat we want our adversarial example to look like: ')\n",
        "    plt.imshow(x_test[idx].reshape((28,28)), cmap='gray')\n",
        "    plt.show()\n",
        "    print('\\n')\n",
        "    print('Adversarial Example: ')\n",
        "    plt.imshow(a.reshape(28,28), cmap='gray')\n",
        "    plt.show()\n",
        "    print('Network Prediction: ' + str(np.argmax(x)) + '\\n')\n",
        "    print('Network Output: \\n' + str(x) + '\\n')\n",
        "    return a\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "print(x_train.shape)\n",
        "x_train = x_train.reshape(60000,28*28)\n",
        "x_test = x_test.reshape(10000,28*28)\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "print(x_train.shape)\n",
        "\n",
        "\n",
        "a = keras.layers.Input(shape=(28*28,))\n",
        "x = keras.layers.Dense(units=512, activation='relu', input_shape=(28*28,))(a)\n",
        "x = keras.layers.Dense(units=128, activation='relu')(x)\n",
        "x = keras.layers.Dense(units=64, activation='relu')(x)\n",
        "x = keras.layers.Dense(units=10, activation='softmax')(x)\n",
        "\n",
        "model = keras.models.Model(inputs=a, outputs=x)\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "\"\"\"\n",
        "a = keras.layers.Input(shape=(28*28,))\n",
        "x = keras.layers.Conv2D(20, (3, 3), padding=\"valid\", activation=tf.nn.relu,)(a)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = keras.layers.Conv2D(50, (3, 3), padding=\"valid\", activation=tf.nn.relu,)(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(225, activation=tf.nn.relu)(x)\n",
        "x = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\"\"\"\n",
        "\n",
        "# sneaky_generate(target label, target digit)\n",
        "adv_ex = sneaky_generate(8, 2)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n",
            "\n",
            "What we want our adversarial example to look like: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adversarial Example: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Network Prediction: 8\n",
            "\n",
            "Network Output: \n",
            "[[0.19 0.11 0.06 0.1  0.07 0.03 0.03 0.12 0.25 0.03]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}