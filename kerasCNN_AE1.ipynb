{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasCNN_AE1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akariiijima/AdversarialExample/blob/master/kerasCNN_AE1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0DbtT1OtdK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4CIRVLvtmIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"mnist_train.csv\")\n",
        "#1-10 labels\n",
        "labels=df[\"5\"].values\n",
        "#one-hot labels\n",
        "labels = tf.keras.utils.to_categorical(labels)\n",
        "\n",
        "df.drop(\"5\", axis=1, inplace=True)\n",
        "pixels=df.values\n",
        "pixels=pixels/255\n",
        "pixels=pixels.reshape(len(df),28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM1Ios5Et54f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Adversarial_Training(keras.models.Model):\n",
        "    _at_loss = None\n",
        "    # set up\n",
        "    def setup_at_loss(self, loss_func=keras.losses.categorical_crossentropy, eps=0.25/255.0):\n",
        "        self._loss_func = loss_func\n",
        "        self._at_loss = self.at_loss(eps)\n",
        "        return self\n",
        "    # VAT loss\n",
        "    def at_loss(self, eps):\n",
        "      \n",
        "        # original loss\n",
        "        loss_orig = self._loss_func(self.inputs[1], self.outputs[0])\n",
        "        \n",
        "        # gradients\n",
        "        map_grads = keras.backend.stop_gradient(keras.backend.gradients(loss_orig, self.inputs[0]))\n",
        "        list_grads = list(map_grads)\n",
        "        grads = list_grads[0]\n",
        "        \n",
        "        #grads = keras.backend.gradients(loss_orig, self.inputs[0])[0]\n",
        "        #loss = F.softmax_cross_entropy(chainer_model(target_array), Variable(np.array([orig_ind.astype(np.int32)])))\n",
        "        #adv_array = self.inputs[0] + eps * keras.backend.sign(target_array.grad)\n",
        "        \n",
        "        # perterbed samples\n",
        "        new_inputs = self.inputs[0] - eps * keras.backend.sign(grads[0])\n",
        "        \n",
        "        # estimation for the perturbated samples\n",
        "        outputs_perturb = self.call([new_inputs, self.inputs[1]])\n",
        "        \n",
        "        # computing losses\n",
        "        loss = self._loss_func(self.inputs[1], outputs_perturb)\n",
        "       \n",
        "        return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiljjIveucMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_pixels=keras.layers.Input(shape=(28, 28,1))\n",
        "model_cnn=keras.layers.Conv2D(20, (3, 3), padding=\"valid\", activation=tf.nn.relu,)(input_pixels)\n",
        "model_cnn=keras.layers.MaxPooling2D(pool_size=(3,3))(model_cnn)\n",
        "model_cnn=keras.layers.Conv2D(50, (3, 3), padding=\"valid\", activation=tf.nn.relu,)(model_cnn)\n",
        "model_cnn=keras.layers.MaxPooling2D(pool_size=(3,3))(model_cnn)\n",
        "model_cnn=keras.layers.BatchNormalization()(model_cnn)\n",
        "model_cnn=keras.layers.Flatten()(model_cnn)\n",
        "model_cnn=keras.layers.Dense(225, activation=tf.nn.relu)(model_cnn)\n",
        "model_cnn=keras.layers.Dense(10, activation=\"softmax\")(model_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAeRR1fNuhJL",
        "colab_type": "code",
        "outputId": "d19736ad-e8de-47f7-89a3-560329b525ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# adversarial training\n",
        "input_label = keras.layers.Input(shape=(10,))\n",
        "model = Adversarial_Training(input=[input_pixels, input_label], output=model_cnn).setup_at_loss(loss_func=keras.losses.categorical_crossentropy, eps=0.25)\n",
        "print(\"input_pixels\" , input_pixels.shape)\n",
        "print(\"input_label\" , input_label.shape)\n",
        "print(\"model_cnn\" , model_cnn.shape)\n",
        "print(model.output)\n",
        "#cnn=keras.models.Model(input=input_pixels, output=cnn)\n",
        "#cnn.compile(optimizer=tf.train.AdamOptimizer(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#print(cnn.predict(pixels).shape)"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Adversarial_Training` call to the Keras 2 API: `Adversarial_Training(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input_pixels (?, 28, 28, 1)\n",
            "input_label (?, 10)\n",
            "model_cnn (?, 10)\n",
            "Tensor(\"dense_92/Softmax:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehIIubi_6TYU",
        "colab_type": "code",
        "outputId": "219dd9c3-91e1-423e-80a2-6aa6ae61ad65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_130 (InputLayer)       (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 26, 26, 20)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling (None, 8, 8, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 6, 6, 50)          9050      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling (None, 2, 2, 50)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 2, 2, 50)          200       \n",
            "_________________________________________________________________\n",
            "flatten_46 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 225)               45225     \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 10)                2260      \n",
            "=================================================================\n",
            "Total params: 56,935\n",
            "Trainable params: 56,835\n",
            "Non-trainable params: 100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IncGFCbk6XKh",
        "colab_type": "code",
        "outputId": "3ed61fc4-bcd1-43b5-e07c-0d1d0f3afbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1887
        }
      },
      "source": [
        "print(pixels.shape)\n",
        "print(labels.shape)\n",
        "print(labels)\n",
        "#model.predict([pixels, labels])\n",
        "#print(model.predict([pixels, labels]).shape)\n",
        "fit=model.fit([pixels, labels],labels,epochs=50, batch_size=4096,validation_split=0.2)"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59999, 28, 28, 1)\n",
            "(59999, 10)\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n",
            "Train on 47999 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "47999/47999 [==============================] - 8s 165us/step - loss: 1.3945 - acc: 0.6110 - val_loss: 0.5939 - val_acc: 0.8581\n",
            "Epoch 2/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.4197 - acc: 0.8920 - val_loss: 0.2818 - val_acc: 0.9110\n",
            "Epoch 3/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.2221 - acc: 0.9332 - val_loss: 0.2007 - val_acc: 0.9373\n",
            "Epoch 4/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.1518 - acc: 0.9542 - val_loss: 0.1761 - val_acc: 0.9439\n",
            "Epoch 5/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.1158 - acc: 0.9656 - val_loss: 0.1652 - val_acc: 0.9478\n",
            "Epoch 6/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0942 - acc: 0.9719 - val_loss: 0.1207 - val_acc: 0.9623\n",
            "Epoch 7/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0797 - acc: 0.9764 - val_loss: 0.1011 - val_acc: 0.9689\n",
            "Epoch 8/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0694 - acc: 0.9794 - val_loss: 0.0926 - val_acc: 0.9724\n",
            "Epoch 9/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0610 - acc: 0.9822 - val_loss: 0.0794 - val_acc: 0.9755\n",
            "Epoch 10/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0543 - acc: 0.9844 - val_loss: 0.0737 - val_acc: 0.9767\n",
            "Epoch 11/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0488 - acc: 0.9862 - val_loss: 0.0640 - val_acc: 0.9803\n",
            "Epoch 12/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0442 - acc: 0.9875 - val_loss: 0.0620 - val_acc: 0.9808\n",
            "Epoch 13/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0401 - acc: 0.9885 - val_loss: 0.0542 - val_acc: 0.9838\n",
            "Epoch 14/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0365 - acc: 0.9898 - val_loss: 0.0522 - val_acc: 0.9848\n",
            "Epoch 15/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0338 - acc: 0.9905 - val_loss: 0.0485 - val_acc: 0.9855\n",
            "Epoch 16/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0310 - acc: 0.9916 - val_loss: 0.0473 - val_acc: 0.9858\n",
            "Epoch 17/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0285 - acc: 0.9925 - val_loss: 0.0479 - val_acc: 0.9859\n",
            "Epoch 18/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0264 - acc: 0.9931 - val_loss: 0.0454 - val_acc: 0.9862\n",
            "Epoch 19/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0244 - acc: 0.9937 - val_loss: 0.0452 - val_acc: 0.9862\n",
            "Epoch 20/50\n",
            "47999/47999 [==============================] - 2s 45us/step - loss: 0.0226 - acc: 0.9941 - val_loss: 0.0440 - val_acc: 0.9869\n",
            "Epoch 21/50\n",
            "47999/47999 [==============================] - 2s 45us/step - loss: 0.0210 - acc: 0.9949 - val_loss: 0.0418 - val_acc: 0.9877\n",
            "Epoch 22/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0194 - acc: 0.9952 - val_loss: 0.0472 - val_acc: 0.9861\n",
            "Epoch 23/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0184 - acc: 0.9955 - val_loss: 0.0413 - val_acc: 0.9878\n",
            "Epoch 24/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0408 - val_acc: 0.9877\n",
            "Epoch 25/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.0412 - val_acc: 0.9872\n",
            "Epoch 26/50\n",
            "47999/47999 [==============================] - 2s 45us/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0421 - val_acc: 0.9871\n",
            "Epoch 27/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0136 - acc: 0.9972 - val_loss: 0.0466 - val_acc: 0.9860\n",
            "Epoch 28/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0388 - val_acc: 0.9889\n",
            "Epoch 29/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0119 - acc: 0.9979 - val_loss: 0.0442 - val_acc: 0.9861\n",
            "Epoch 30/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0400 - val_acc: 0.9880\n",
            "Epoch 31/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0104 - acc: 0.9983 - val_loss: 0.0456 - val_acc: 0.9858\n",
            "Epoch 32/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0096 - acc: 0.9985 - val_loss: 0.0441 - val_acc: 0.9859\n",
            "Epoch 33/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0090 - acc: 0.9987 - val_loss: 0.0393 - val_acc: 0.9881\n",
            "Epoch 34/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0084 - acc: 0.9989 - val_loss: 0.0396 - val_acc: 0.9887\n",
            "Epoch 35/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0079 - acc: 0.9989 - val_loss: 0.0437 - val_acc: 0.9862\n",
            "Epoch 36/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0430 - val_acc: 0.9869\n",
            "Epoch 37/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.0389 - val_acc: 0.9881\n",
            "Epoch 38/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0065 - acc: 0.9993 - val_loss: 0.0386 - val_acc: 0.9883\n",
            "Epoch 39/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0405 - val_acc: 0.9880\n",
            "Epoch 40/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0420 - val_acc: 0.9869\n",
            "Epoch 41/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0411 - val_acc: 0.9878\n",
            "Epoch 42/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0051 - acc: 0.9996 - val_loss: 0.0392 - val_acc: 0.9885\n",
            "Epoch 43/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0047 - acc: 0.9997 - val_loss: 0.0387 - val_acc: 0.9885\n",
            "Epoch 44/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0045 - acc: 0.9998 - val_loss: 0.0414 - val_acc: 0.9877\n",
            "Epoch 45/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0043 - acc: 0.9998 - val_loss: 0.0391 - val_acc: 0.9885\n",
            "Epoch 46/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.0386 - val_acc: 0.9885\n",
            "Epoch 47/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.0386 - val_acc: 0.9885\n",
            "Epoch 48/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.0392 - val_acc: 0.9878\n",
            "Epoch 49/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9877\n",
            "Epoch 50/50\n",
            "47999/47999 [==============================] - 2s 44us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j0U1Kh-5DM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test=pd.read_csv(\"mnist_test.csv\")\n",
        "#1-10 labels\n",
        "labels_test=df_test[\"7\"].values\n",
        "#one-hot labels\n",
        "labels_test = tf.keras.utils.to_categorical(labels_test)\n",
        "\n",
        "df_test.drop(\"7\", axis=1, inplace=True)\n",
        "pixels_test=df_test.values\n",
        "pixels_test=pixels_test/255\n",
        "pixels_test=pixels_test.reshape(len(df_test),28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ViEgpNT0RTn",
        "colab_type": "code",
        "outputId": "446f2cd7-e02e-4052-c47c-c6baef78d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "adversarialExample_test = np.tile(np.array([1.,0.,0.,0.,0.,0.,0.,0.,0.,0.]),(len(df_test),1))\n",
        "test_loss, test_acc = model.evaluate([pixels_test, labels_test],labels_test)\n",
        "\n",
        "print(\"Test_loss:\", test_loss)\n",
        "print(\"Test_accuracy:\", test_acc)"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9999/9999 [==============================] - 1s 80us/step\n",
            "Test_loss: 0.0326302270295655\n",
            "Test_accuracy: 0.9906990699069907\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}